import time

import gradio as gr
import numpy as np
import soundfile as sf

from .audio_processing import apply_fade
from .context import require_clip_manager
from .music_generation import auto_generate_music_from_score, generate_music_from_clips
from .pitch import detect_pitch_advanced
from .score_parser import parse_score_notes
from .serialization import convert_to_serializable
from .visualization import create_enhanced_analysis, create_spectrogram


def handle_audio_upload(audio_input, target_note, auto_detect, analysis_mode):
    """å¤„ç†éŸ³é¢‘ä¸Šä¼ """
    clip_manager = require_clip_manager()

    if audio_input is None:
        return "è¯·å…ˆä¸Šä¼ éŸ³é¢‘æ–‡ä»¶", None, None, None

    # è¯»å–éŸ³é¢‘
    if isinstance(audio_input, tuple):
        sr, y = audio_input
        y = np.array(y, dtype=np.float32)
    elif isinstance(audio_input, dict):
        sr, y = audio_input["sample_rate"], np.array(audio_input["data"], dtype=np.float32)
    elif isinstance(audio_input, str):
        y, sr = sf.read(audio_input)
        if y.ndim > 1:
            y = np.mean(y, axis=1)
    else:
        return "ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼", None, None, None

    # æ£€æµ‹éŸ³é«˜
    note_info = detect_pitch_advanced(y, sr)

    message = []

    if note_info["frequency"]:
        message.append(f"æ£€æµ‹åˆ°é¢‘ç‡: **{note_info['frequency']:.1f} Hz**")
        message.append(f"éŸ³å: **{note_info['note']}**")
        message.append(f"éŸ³åˆ†åå·®: **{note_info['cents']:+.1f} cents**")
        message.append(f"ç½®ä¿¡åº¦: **{note_info['confidence']:.2%}**")

        if note_info["stable"]:
            message.append("âœ… éŸ³é«˜ç¨³å®š")
        else:
            message.append("âš ï¸ éŸ³é«˜ä¸ç¨³å®šï¼Œå¯èƒ½åŒ…å«æ»‘éŸ³æˆ–å¤šéŸ³")
    else:
        message.append("âŒ æ— æ³•æ£€æµ‹åˆ°ç¨³å®šéŸ³é«˜")

    # å¦‚æœæœ‰ç›®æ ‡éŸ³é«˜ï¼Œè¿›è¡Œæ¯”è¾ƒ
    if target_note:
        from .theory import midi_to_freq, note_to_midi, freq_to_midi

        target_midi = note_to_midi(target_note)
        if target_midi:
            target_freq = midi_to_freq(target_midi)
            if note_info["frequency"]:
                cents_diff = (freq_to_midi(note_info["frequency"]) - target_midi) * 100
                message.append(f"ç›®æ ‡éŸ³é«˜: **{target_note}** ({target_freq:.1f} Hz)")
                message.append(f"åå·®: **{cents_diff:+.1f} cents**")

                if abs(cents_diff) <= 50:
                    message.append("âœ… åœ¨å¯æ¥å—èŒƒå›´å†… (Â±50 cents)")
                else:
                    message.append("âš ï¸ åå·®è¾ƒå¤§")
        else:
            message.append(f"âŒ ç›®æ ‡éŸ³é«˜ '{target_note}' æ ¼å¼é”™è¯¯")

    # ä¿å­˜ç‰‡æ®µ
    clip_info = clip_manager.add_clip(
        y,
        sr,
        note_info=convert_to_serializable(note_info) if note_info else None,
        metadata={
            "target_note": str(target_note) if target_note else "",
            "upload_time": str(time.strftime("%Y-%m-%d %H:%M:%S")),
        },
    )

    # ç”Ÿæˆå›¾è¡¨
    if analysis_mode == "simple":
        fig = create_spectrogram(y, sr, note_info.get("frequency"))
        fig2 = None
    else:
        fig = create_spectrogram(y, sr, note_info.get("frequency"))
        fig2 = create_enhanced_analysis(y, sr, note_info)

    return "\n".join(message), clip_info["id"], fig, fig2


def process_audio_clip(clip_id, operation, value):
    """å¤„ç†éŸ³é¢‘ç‰‡æ®µï¼ˆå˜é€Ÿ/å˜è°ƒï¼‰"""
    clip_manager = require_clip_manager()

    if not 0 <= clip_id < len(clip_manager.clips):
        return "æ— æ•ˆçš„ç‰‡æ®µID", None

    clip = clip_manager.clips[clip_id]
    y, sr = sf.read(clip["filepath"])
    if y.ndim > 1:
        y = np.mean(y, axis=1)

    if operation == "time_stretch":
        target_duration = float(value)
        from .audio_processing import time_stretch

        y_processed = time_stretch(y, sr, target_duration)
        message = f"æ—¶é•¿è°ƒæ•´ä¸º {target_duration:.2f} ç§’"
    elif operation == "pitch_shift":
        semitones = float(value)
        from .audio_processing import pitch_shift

        y_processed = pitch_shift(y, sr, semitones)
        message = f"éŸ³é«˜è°ƒæ•´ {semitones:+.1f} ä¸ªåŠéŸ³"
    else:
        return "æœªçŸ¥æ“ä½œ", None

    # åº”ç”¨æ·¡å…¥æ·¡å‡º
    y_processed = apply_fade(y_processed, sr)

    # ä¿å­˜å¤„ç†åçš„éŸ³é¢‘
    processed_info = clip_manager.add_clip(
        y_processed,
        sr,
        metadata={
            "original_clip_id": clip_id,
            "operation": operation,
            "value": value,
            "processed_time": time.strftime("%Y-%m-%d %H:%M:%S"),
        },
    )

    return f"âœ… {message} (æ–°ç‰‡æ®µID: {processed_info['id']})", (sr, y_processed)


def build_music_composition_tab():
    """æ„å»ºå…¨æ–°çš„è‡ªåŠ¨éŸ³ä¹åˆ¶ä½œç•Œé¢"""

    with gr.TabItem("ğŸ¼ æ™ºèƒ½éŸ³ä¹åˆ¶ä½œ"):
        gr.Markdown(
            """
        ## ğŸ¼ æ™ºèƒ½éŸ³ä¹åˆ¶ä½œå·¥ä½œå°
        ä¸Šä¼ ä¹è°± â†’ è‡ªåŠ¨åŒ¹é…éŸ³é¢‘ç‰‡æ®µ â†’ æ™ºèƒ½å˜è°ƒå¤„ç† â†’ ç”Ÿæˆå®Œæ•´éŸ³ä¹
        """
        )

        with gr.Row():
            with gr.Column(scale=1):
                # ä¹è°±ä¸Šä¼ åŒºåŸŸ
                gr.Markdown("### 1. ä¸Šä¼ ä¹è°±")
                score_upload = gr.File(
                    label="é€‰æ‹©ä¹è°±æ–‡ä»¶",
                    file_types=[".xml", ".musicxml", ".mid", ".midi"],
                    type="filepath",
                )

                # ä¹è°±ä¿¡æ¯å±•ç¤º
                score_info = gr.Markdown("ç­‰å¾…ä¸Šä¼ ä¹è°±...", label="ä¹è°±ä¿¡æ¯")

                # å¤„ç†é€‰é¡¹
                gr.Markdown("### 2. å¤„ç†é€‰é¡¹")

                with gr.Row():
                    match_tolerance = gr.Slider(
                        minimum=0,
                        maximum=100,
                        value=20,
                        step=5,
                        label="éŸ³é«˜åŒ¹é…å®¹å·® (cents)",
                        info="å€¼è¶Šå°åŒ¹é…è¦æ±‚è¶Šä¸¥æ ¼",
                    )

                    use_pitch_shift = gr.Checkbox(
                        label="å¯ç”¨æ™ºèƒ½å˜è°ƒ",
                        value=True,
                        info="å¯¹ä¸åŒ¹é…çš„éŸ³ç¬¦è‡ªåŠ¨å˜è°ƒå¤„ç†",
                    )

                tempo_input = gr.Slider(
                    label="æ¼”å¥é€Ÿåº¦ (BPM)",
                    minimum=40,
                    maximum=240,
                    value=120,
                    step=5,
                )

                # ç”ŸæˆæŒ‰é’®
                btn_generate = gr.Button("ğŸµ è‡ªåŠ¨ç”ŸæˆéŸ³ä¹", variant="primary", size="lg")
                generation_status = gr.Markdown("å‡†å¤‡ç”Ÿæˆ...", label="ç”ŸæˆçŠ¶æ€")

            with gr.Column(scale=2):
                # ç”Ÿæˆç»“æœåŒºåŸŸ
                gr.Markdown("### 3. ç”Ÿæˆç»“æœ")

                with gr.Tabs():
                    with gr.TabItem("ğŸ§ è¯•å¬éŸ³ä¹"):
                        composition_audio = gr.Audio(label="ç”ŸæˆéŸ³ä¹", type="numpy")

                    with gr.TabItem("ğŸ“Š ç”ŸæˆæŠ¥å‘Š"):
                        generation_report = gr.Markdown("ç”ŸæˆæŠ¥å‘Šå°†åœ¨æ­¤æ˜¾ç¤º...", label="è¯¦ç»†æŠ¥å‘Š")

                    with gr.TabItem("ğŸ§© éŸ³ç¬¦åŒ¹é…è¯¦æƒ…"):
                        notes_match_table = gr.Dataframe(
                            headers=["åºå·", "éŸ³å", "åŒ¹é…ç‰‡æ®µ", "å˜è°ƒ(åŠéŸ³)", "çŠ¶æ€", "éŸ³è½¨", "ä¹å™¨"],
                            label="éŸ³ç¬¦åŒ¹é…æƒ…å†µ",
                            datatype=["str", "str", "str", "str", "str", "str", "str"],
                            row_count=10,
                            interactive=False,
                        )

        # è¿æ¥ç”ŸæˆæŒ‰é’®
        btn_generate.click(
            fn=auto_generate_music_from_score,
            inputs=[score_upload, tempo_input, match_tolerance, use_pitch_shift],
            outputs=[composition_audio, generation_report, notes_match_table, generation_status],
        )

        # ä¹è°±ä¸Šä¼ åçš„é¢„è§ˆ
        def preview_score(filepath):
            if filepath is None:
                return "ç­‰å¾…ä¸Šä¼ ä¹è°±...", []

            try:
                notes = parse_score_notes(filepath)
                if not notes:
                    return "æœªèƒ½ä»ä¹è°±ä¸­è§£æå‡ºéŸ³ç¬¦", []

                # æ„å»ºé¢„è§ˆä¿¡æ¯
                preview_text = "### ä¹è°±è§£ææˆåŠŸï¼\n"
                preview_text += f"**éŸ³ç¬¦æ€»æ•°**: {len(notes)}\n"
                preview_text += f"**éŸ³é«˜èŒƒå›´**: {notes[0]['note_name']} åˆ° {notes[-1]['note_name']}\n"
                preview_text += f"**æ€»æ—¶é•¿**: {sum(n['duration'] for n in notes):.2f} æ‹\n\n"
                preview_text += "**å‰10ä¸ªéŸ³ç¬¦**:\n"

                # æ„å»ºè¡¨æ ¼æ•°æ®
                table_data = []
                for i, note in enumerate(notes[:10]):
                    table_data.append(
                        [
                            i + 1,
                            note["note_name"],
                            f"{note['duration']:.2f}æ‹",
                            f"{note['start_time']:.2f}æ‹",
                            "æ˜¯" if note["matched"] else "å¦",
                        ]
                    )

                preview_text += "(è¯¦ç»†åŒ¹é…æƒ…å†µå°†åœ¨ç”Ÿæˆæ—¶æ˜¾ç¤º)"
                return preview_text, table_data

            except Exception as exc:
                return f"è§£æä¹è°±æ—¶å‡ºé”™: {str(exc)}", []

        score_upload.change(
            fn=preview_score, inputs=[score_upload], outputs=[score_info, notes_match_table]
        )


def build_advanced_ui():
    with gr.Blocks(title="é«˜çº§éŸ³é¢‘å¤„ç†ä¸éŸ³ä¹åˆ¶ä½œç³»ç»Ÿ", theme=gr.themes.Soft()) as demo:
        gr.Markdown(
            """
        # ğŸ›ï¸ é«˜çº§éŸ³é¢‘å¤„ç†ä¸éŸ³ä¹åˆ¶ä½œç³»ç»Ÿ

        ## åŠŸèƒ½ä»‹ç»
        1. **éŸ³é¢‘è¯†åˆ«**ï¼šè‡ªåŠ¨æ£€æµ‹éŸ³é¢‘é¢‘ç‡å¹¶è½¬æ¢ä¸ºéŸ³å
        2. **éŸ³é¢‘å¤„ç†**ï¼šæ”¯æŒå˜é€Ÿã€å˜è°ƒã€æ·¡å…¥æ·¡å‡º
        3. **éŸ³ä¹åˆ¶ä½œ**ï¼šæ ¹æ®ä¹è°±æˆ–æ‰‹åŠ¨ç¼–æ’åˆ¶ä½œéŸ³ä¹
        4. **é¢‘è°±åˆ†æ**ï¼šå¯è§†åŒ–éŸ³é¢‘ç‰¹å¾
        """
        )

        with gr.Tabs():
            with gr.TabItem("ğŸ™ï¸ éŸ³é¢‘ä¸Šä¼ ä¸è¯†åˆ«"):
                with gr.Row():
                    with gr.Column(scale=1):
                        audio_input = gr.Audio(label="ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶", type="filepath")
                        target_note = gr.Textbox(
                            label="ç›®æ ‡éŸ³é«˜ï¼ˆå¯é€‰ï¼‰",
                            placeholder="ä¾‹å¦‚ï¼šC4, D#4, Gb5",
                            value="",
                        )

                        with gr.Row():
                            auto_detect = gr.Checkbox(label="è‡ªåŠ¨æ£€æµ‹éŸ³é«˜", value=True)
                            analysis_mode = gr.Radio(
                                choices=["simple", "enhanced"],
                                label="åˆ†ææ¨¡å¼",
                                value="simple",
                                info="ç®€å•æ¨¡å¼ï¼šé¢‘è°±å›¾+æ³¢å½¢å›¾ | å¢å¼ºæ¨¡å¼ï¼šå¤šç§åˆ†æå›¾è¡¨",
                            )

                        btn_analyze = gr.Button("åˆ†æéŸ³é¢‘", variant="primary")

                    with gr.Column(scale=2):
                        result_text = gr.Markdown(label="åˆ†æç»“æœ")
                        clip_id_output = gr.Number(label="ç‰‡æ®µID", visible=False)
                        spectrogram = gr.Plot(label="é¢‘è°±å›¾åˆ†æ")
                        enhanced_analysis = gr.Plot(label="å¢å¼ºåˆ†æ", visible=False)

                        def toggle_analysis(analysis_mode):
                            if analysis_mode == "enhanced":
                                return gr.Plot(visible=True)
                            return gr.Plot(visible=False)

                        analysis_mode.change(
                            fn=toggle_analysis, inputs=[analysis_mode], outputs=[enhanced_analysis]
                        )

                btn_analyze.click(
                    fn=handle_audio_upload,
                    inputs=[audio_input, target_note, auto_detect, analysis_mode],
                    outputs=[result_text, clip_id_output, spectrogram, enhanced_analysis],
                )

                # é¢‘è°±å›¾è¯´æ˜
                with gr.Accordion("ğŸ“ˆ é¢‘è°±å›¾è§£è¯»æŒ‡å—", open=False):
                    gr.Markdown(
                        """
                    ### å¦‚ä½•è¯»æ‡‚é¢‘è°±å›¾ï¼š

                    1. **æ—¶é—´è½´ï¼ˆXè½´ï¼‰**ï¼šä»å·¦åˆ°å³è¡¨ç¤ºéŸ³é¢‘çš„æ—¶é—´è¿›åº¦
                    2. **é¢‘ç‡è½´ï¼ˆYè½´ï¼‰**ï¼šä»ä¸‹åˆ°ä¸Šè¡¨ç¤ºå£°éŸ³é¢‘ç‡ï¼ˆä½éŸ³åœ¨ä¸‹ï¼Œé«˜éŸ³åœ¨ä¸Šï¼‰
                    3. **é¢œè‰²æ·±æµ…**ï¼šè¡¨ç¤ºéŸ³é‡å¤§å°
                       - **æ·±è‰²/è“è‰²**ï¼šå®‰é™çš„å£°éŸ³
                       - **äº®è‰²/é»„è‰²**ï¼šå“äº®çš„å£°éŸ³
                    4. **çº¢è‰²è™šçº¿**ï¼šæ£€æµ‹åˆ°çš„ä¸»éŸ³é«˜é¢‘ç‡
                    5. **åº•éƒ¨æ³¢å½¢å›¾**ï¼šéŸ³é¢‘çš„æŒ¯å¹…å˜åŒ–

                    ### å¸¸è§éŸ³é¢‘åœ¨é¢‘è°±å›¾ä¸Šçš„è¡¨ç°ï¼š
                    - **çº¯éŸ³/ä¹å™¨å•éŸ³**ï¼šä¸€æ¡æ¸…æ™°çš„æ°´å¹³çº¿
                    - **äººå£°/å¤æ‚éŸ³è‰²**ï¼šå¤šæ¡æ°´å¹³çº¿ï¼ˆåŸºé¢‘+æ³›éŸ³ï¼‰
                    - **å™ªéŸ³/æ‰“å‡»ä¹**ï¼šå‚ç›´çš„è‰²å—ï¼ˆçŸ­æš‚çˆ†å‘ï¼‰
                    - **é™éŸ³**ï¼šæ·±è‰²æˆ–é»‘è‰²åŒºåŸŸ

                    ### å¦‚ä½•åˆ¤æ–­éŸ³é«˜ï¼š
                    - å¯»æ‰¾æœ€äº®çš„æ°´å¹³çº¿æ¡
                    - å¯¹ç…§å³ä¾§é¢‘ç‡æ ‡å°º
                    - çº¢è‰²è™šçº¿æ ‡è®°çš„æ˜¯ç³»ç»Ÿæ£€æµ‹åˆ°çš„ä¸»é¢‘ç‡
                    """
                    )

            with gr.TabItem("ğŸ› ï¸ éŸ³é¢‘å¤„ç†"):
                with gr.Row():
                    with gr.Column(scale=1):
                        clip_id_input = gr.Number(label="ç‰‡æ®µID", value=0, precision=0)
                        operation = gr.Radio(
                            choices=["time_stretch", "pitch_shift"],
                            label="å¤„ç†ç±»å‹",
                            value="time_stretch",
                        )
                        value_input = gr.Slider(
                            label="å‚æ•°å€¼",
                            minimum=0.1,
                            maximum=5.0,
                            value=1.0,
                            step=0.1,
                            visible=True,
                        )

                        def update_slider(operation):
                            if operation == "time_stretch":
                                return gr.Slider(
                                    minimum=0.1,
                                    maximum=5.0,
                                    value=1.0,
                                    step=0.1,
                                    label="ç›®æ ‡æ—¶é•¿ï¼ˆç§’ï¼‰",
                                )
                            return gr.Slider(
                                minimum=-12,
                                maximum=12,
                                value=0,
                                step=0.5,
                                label="åŠéŸ³ç§»åŠ¨",
                            )

                        operation.change(fn=update_slider, inputs=[operation], outputs=[value_input])

                        btn_process = gr.Button("å¤„ç†éŸ³é¢‘", variant="primary")
                        process_result = gr.Markdown(label="å¤„ç†ç»“æœ")

                    with gr.Column(scale=2):
                        audio_preview = gr.Audio(label="å¤„ç†ç»“æœé¢„è§ˆ", type="numpy")

                btn_process.click(
                    fn=process_audio_clip,
                    inputs=[clip_id_input, operation, value_input],
                    outputs=[process_result, audio_preview],
                )

            with gr.TabItem("ğŸµ éŸ³ä¹åˆ¶ä½œ"):
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown(
                            """
                        ### éŸ³ä¹ç¼–æ’è¯´æ˜

                        æ ¼å¼ï¼š`æ‹æ•°:ç‰‡æ®µID, æ‹æ•°:ç‰‡æ®µID, ...`

                        ç¤ºä¾‹ï¼š
                        ```
                        0:0, 1:1, 2:2, 4:3
                        ```

                        è¡¨ç¤ºï¼š
                        - ç¬¬0æ‹ä½¿ç”¨ç‰‡æ®µ0
                        - ç¬¬1æ‹ä½¿ç”¨ç‰‡æ®µ1  
                        - ç¬¬2æ‹ä½¿ç”¨ç‰‡æ®µ2
                        - ç¬¬4æ‹ä½¿ç”¨ç‰‡æ®µ3
                        """
                        )

                        clip_assignments = gr.Textbox(
                            label="ç‰‡æ®µåˆ†é…",
                            placeholder="æ ¼å¼: æ‹æ•°:ç‰‡æ®µID, æ‹æ•°:ç‰‡æ®µID,...",
                            lines=3,
                        )
                        tempo_input = gr.Slider(
                            label="é€Ÿåº¦ (BPM)",
                            minimum=40,
                            maximum=240,
                            value=120,
                            step=10,
                        )
                        btn_compose = gr.Button("ç”ŸæˆéŸ³ä¹", variant="primary")
                        compose_result = gr.Markdown(label="ç”Ÿæˆç»“æœ")

                    with gr.Column(scale=2):
                        composition_audio = gr.Audio(label="ç”ŸæˆéŸ³ä¹", type="numpy")

                btn_compose.click(
                    fn=generate_music_from_clips,
                    inputs=[clip_assignments, tempo_input],
                    outputs=[compose_result, composition_audio],
                )

            with gr.TabItem("ğŸ“ ç‰‡æ®µç®¡ç†"):
                clip_manager = require_clip_manager()

                def update_clips_table():
                    clips = clip_manager.get_all_clips()
                    table_data = []
                    for clip in clips:
                        note_info = clip.get("note_info", {})
                        table_data.append(
                            [
                                clip["id"],
                                clip["filename"],
                                note_info.get("note", "æœªçŸ¥"),
                                f"{note_info.get('frequency', 0):.1f}"
                                if note_info.get("frequency")
                                else "æœªçŸ¥",
                                f"{note_info.get('cents', 0):+.1f}"
                                if note_info.get("cents") is not None
                                else "",
                                f"{clip['duration']:.2f}",
                                clip["created_at"],
                            ]
                        )
                    return table_data

                with gr.Row():
                    clips_table = gr.Dataframe(
                        headers=["ID", "æ–‡ä»¶å", "éŸ³å", "é¢‘ç‡", "åå·®", "æ—¶é•¿", "åˆ›å»ºæ—¶é—´"],
                        label="æ‰€æœ‰éŸ³é¢‘ç‰‡æ®µ",
                        datatype=["number", "str", "str", "str", "str", "str", "str"],
                        row_count=10,
                        col_count=7,
                        interactive=False,
                    )

                with gr.Row():
                    btn_refresh = gr.Button("åˆ·æ–°åˆ—è¡¨")
                    delete_clip_id = gr.Number(label="åˆ é™¤ç‰‡æ®µID", value=0, precision=0)
                    btn_delete = gr.Button("åˆ é™¤ç‰‡æ®µ", variant="stop")

                with gr.Row():
                    btn_cleanup = gr.Button("æ¸…ç†å­¤ç«‹æ–‡ä»¶", variant="secondary")

                def cleanup_orphaned():
                    clip_manager.cleanup_orphaned_files()
                    return "å·²æ¸…ç†å­¤ç«‹æ–‡ä»¶", update_clips_table()

                btn_cleanup.click(fn=cleanup_orphaned, inputs=[], outputs=[compose_result, clips_table])

                def delete_selected_clip(clip_id):
                    success = clip_manager.delete_clip(int(clip_id))
                    if success:
                        return f"âœ… å·²åˆ é™¤ç‰‡æ®µ {clip_id}", update_clips_table()
                    return f"âŒ åˆ é™¤å¤±è´¥ï¼Œç‰‡æ®µ {clip_id} ä¸å­˜åœ¨", update_clips_table()

                btn_refresh.click(fn=update_clips_table, inputs=[], outputs=[clips_table])

                btn_delete.click(
                    fn=delete_selected_clip, inputs=[delete_clip_id], outputs=[compose_result, clips_table]
                )

            build_music_composition_tab()
        gr.Markdown(
            """
        ## ğŸ“˜ ä½¿ç”¨è¯´æ˜

        ### 1. éŸ³é¢‘è¯†åˆ«
        - ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼ˆæ”¯æŒwav, mp3ç­‰æ ¼å¼ï¼‰
        - ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹éŸ³é«˜å¹¶æ˜¾ç¤ºé¢‘è°±å›¾
        - å¯è¾“å…¥ç›®æ ‡éŸ³é«˜è¿›è¡Œæ¯”è¾ƒ

        ### 2. éŸ³é¢‘å¤„ç†
        - **æ—¶é—´æ‹‰ä¼¸**ï¼šè°ƒæ•´éŸ³é¢‘æ—¶é•¿è€Œä¸æ”¹å˜éŸ³é«˜
        - **éŸ³é«˜ç§»åŠ¨**ï¼šè°ƒæ•´éŸ³é«˜è€Œä¸æ”¹å˜æ—¶é•¿
        - å¤„ç†åçš„éŸ³é¢‘ä¼šä¿å­˜ä¸ºæ–°ç‰‡æ®µ

        ### 3. éŸ³ä¹åˆ¶ä½œ
        - å°†éŸ³é¢‘ç‰‡æ®µåˆ†é…åˆ°ç‰¹å®šçš„æ‹æ•°ä½ç½®
        - è°ƒæ•´éŸ³ä¹é€Ÿåº¦ï¼ˆBPMï¼‰
        - ç³»ç»Ÿä¼šè‡ªåŠ¨æ‹¼æ¥ç”Ÿæˆå®Œæ•´éŸ³ä¹

        ### 4. é¢‘è°±å›¾è§£è¯»
        - **æ°´å¹³çº¿**ï¼šç¨³å®šçš„éŸ³é«˜
        - **å‚ç›´çº¿**ï¼šç¬æ—¶å£°éŸ³ï¼ˆå¦‚é¼“ç‚¹ï¼‰
        - **é¢œè‰²æ·±æµ…**ï¼šéŸ³é‡å¤§å°
        - **çº¢è‰²è™šçº¿**ï¼šæ£€æµ‹åˆ°çš„ä¸»é¢‘ç‡

        ## âš™ï¸ å®‰è£…è¯´æ˜
        ```bash
        # åŸºæœ¬ä¾èµ–
        pip install gradio librosa numpy soundfile matplotlib scipy

        # è§£å†³ä¸­æ–‡å­—ä½“é—®é¢˜ï¼ˆWindowsï¼‰
        # ç¡®ä¿ç³»ç»Ÿå·²å®‰è£…ä¸­æ–‡å­—ä½“ï¼ˆå¦‚å¾®è½¯é›…é»‘ï¼‰

        # è§£å†³ä¸­æ–‡å­—ä½“é—®é¢˜ï¼ˆLinuxï¼‰
        sudo apt-get install fonts-wqy-microhei
        ```
        """
        )

    return demo
